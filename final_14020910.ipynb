{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (9.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.15.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.13)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hojat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url\n",
    "https://www.google.com/search?q=dogs&tbm=isch&ved=2ahUKEwjyi4_tuO6CAxUq9qACHUedBj0Q2-cCegQIABAA&oq=dogs&gs_lcp=CgNpbWcQAzINCAAQgAQQigUQQxCxAzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzIKCAAQgAQQigUQQzoECCMQJzoFCAAQgAQ6BwgjEOoCECc6DggAEIAEEIoFELEDEIMBOggIABCABBCxAzoQCAAQgAQQigUQQxCxAxCDAVDwBVihF2DOHWgBcAB4AoAB_AK#IAfUWkgEDMy04mAEAoAEBqgELZ3dzLXdpei1pbWewAQrAAQE&sclient=img&ei=Ee1pZbK_LKrsg8UPx7qa6AM&bih=786&biw=1707&rlz=1C1GCEB_enIR1026IR1026#imgrc=IJz6FunUM88BkM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version1:\n",
    "define URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1\n",
      "Found 2\n",
      "Found 3\n",
      "Found 4\n",
      "Found 5\n",
      "Found 6\n",
      "Found 7\n",
      "Found 8\n",
      "Found 9\n",
      "Found 10\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "FAILED - cannot identify image file <_io.BytesIO object at 0x0000025910202520>\n",
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "\n",
    "# Function to get input from user\n",
    "def get_user_input():\n",
    "    max_images = int(input(\"Enter the maximum number of photos to download: \"))\n",
    "    url = input(\"Enter the URL for scraping images: \")\n",
    "    download_path = input(\"Enter the location for downloading the photos: \")\n",
    "    return max_images, url, download_path\n",
    "\n",
    "# Specify the correct path to your chromedriver.exe\n",
    "PATH = \"...\\chromedriver.exe\"\n",
    "service = Service(PATH)\n",
    "wd = webdriver.Chrome(service=service)\n",
    "\n",
    "def get_images_from_google(wd, url, delay, max_images):\n",
    "\tdef scroll_down(wd):\n",
    "\t\twd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\t\ttime.sleep(delay)\n",
    "\n",
    "\turl = url\n",
    "\twd.get(url)\n",
    "\n",
    "\timage_urls = set()\n",
    "\tskips = 0\n",
    "\n",
    "\twhile len(image_urls) + skips < max_images:\n",
    "\t\tscroll_down(wd)\n",
    "\n",
    "\t\tthumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "\n",
    "\t\tfor img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "\t\t\ttry:\n",
    "\t\t\t\timg.click()\n",
    "\t\t\t\ttime.sleep(delay)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\timages = wd.find_elements(By.CLASS_NAME, \"iPVvYb\" or \"pT0Scc\")\n",
    "\t\t\tfor image in images:\n",
    "\t\t\t\tif image.get_attribute('src') in image_urls:\n",
    "\t\t\t\t\tmax_images += 1\n",
    "\t\t\t\t\tskips += 1\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "\t\t\t\t\timage_urls.add(image.get_attribute('src'))\n",
    "\t\t\t\t\tprint(f\"Found {len(image_urls)}\")\n",
    "\n",
    "\treturn image_urls\n",
    "\n",
    "\n",
    "def download_image(download_path, url, file_name):\n",
    "\ttry:\n",
    "\t\timage_content = requests.get(url).content\n",
    "\t\timage_file = io.BytesIO(image_content)\n",
    "\t\timage = Image.open(image_file)\n",
    "\t\tfile_path = download_path + file_name\n",
    "\n",
    "\t\twith open(file_path, \"wb\") as f:\n",
    "\t\t\timage.save(f, \"JPEG\")\n",
    "\n",
    "\t\tprint(\"Success\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint('FAILED -', e)\n",
    "  \n",
    "# Get user input\n",
    "max_images, url, download_path = get_user_input()\n",
    "\n",
    "# Adjust the function calls accordingly\n",
    "urls = get_images_from_google(wd, url, 1, max_images)\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    download_image(download_path, url, str(i) + \".jpg\")\n",
    "\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version2:\n",
    "Define title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "\n",
    "# Function to get input from user\n",
    "def get_user_input():\n",
    "    max_images = int(input(\"Enter the maximum number of photos to download: \"))\n",
    "    search_term = input(\"Enter the search term for images: \")\n",
    "    download_path = input(\"Enter the location for downloading the photos: \")\n",
    "    return max_images, search_term, download_path\n",
    "\n",
    "# Function to create a Google Images URL from the search term\n",
    "def create_google_images_url(search_term):\n",
    "    base_url = \"https://www.google.com/search?tbm=isch&q=\"\n",
    "    query = quote_plus(search_term)\n",
    "    return f\"{base_url}{query}\"\n",
    "\n",
    "\n",
    "# Specify the correct path to your chromedriver.exe\n",
    "PATH = \"...\\chromedriver.exe\"\n",
    "service = Service(PATH)\n",
    "wd = webdriver.Chrome(service=service)\n",
    "\n",
    "def get_images_from_google(wd, url, delay, max_images):\n",
    "\tdef scroll_down(wd):\n",
    "\t\twd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\t\ttime.sleep(delay)\n",
    "\n",
    "\turl = url\n",
    "\twd.get(url)\n",
    "\n",
    "\timage_urls = set()\n",
    "\tskips = 0\n",
    "\n",
    "\twhile len(image_urls) + skips < max_images:\n",
    "\t\tscroll_down(wd)\n",
    "\n",
    "\t\tthumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "\n",
    "\t\tfor img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "\t\t\ttry:\n",
    "\t\t\t\timg.click()\n",
    "\t\t\t\ttime.sleep(delay)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\timages = wd.find_elements(By.CLASS_NAME, \"iPVvYb\")\n",
    "\t\t\tfor image in images:\n",
    "\t\t\t\tif image.get_attribute('src') in image_urls:\n",
    "\t\t\t\t\tmax_images += 1\n",
    "\t\t\t\t\tskips += 1\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "\t\t\t\t\timage_urls.add(image.get_attribute('src'))\n",
    "\t\t\t\t\tprint(f\"Found {len(image_urls)}\")\n",
    "\n",
    "\treturn image_urls\n",
    "\n",
    "\n",
    "def download_image(download_path, url, file_name):\n",
    "\ttry:\n",
    "\t\timage_content = requests.get(url).content\n",
    "\t\timage_file = io.BytesIO(image_content)\n",
    "\t\timage = Image.open(image_file)\n",
    "\t\tfile_path = download_path + file_name\n",
    "\n",
    "\t\twith open(file_path, \"wb\") as f:\n",
    "\t\t\timage.save(f, \"JPEG\")\n",
    "\n",
    "\t\tprint(\"Success\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint('FAILED -', e)\n",
    "  \n",
    "# Get user input\n",
    "max_images, search_term, download_path = get_user_input()\n",
    "url = create_google_images_url(search_term)\n",
    "\n",
    "# Adjust the function calls accordingly\n",
    "urls = get_images_from_google(wd, url, 1, max_images)\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    download_image(download_path, url, str(i) + \".jpg\")\n",
    "\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version3:\n",
    "Define App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# Function to create a Google Images URL from the search term\n",
    "def create_google_images_url(search_term):\n",
    "    base_url = \"https://www.google.com/search?tbm=isch&q=\"\n",
    "    query = quote_plus(search_term)\n",
    "    return f\"{base_url}{query}\"\n",
    "\n",
    "# Function to get images from Google\n",
    "def get_images_from_google(wd, url, delay, max_images):\n",
    "    def scroll_down(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    wd.get(url)\n",
    "    image_urls = set()\n",
    "    skips = 0\n",
    "    i = 0\n",
    "    while len(image_urls) + skips < max_images:\n",
    "        \n",
    "        thumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "\n",
    "        for img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(delay)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            images = wd.find_elements(By.CLASS_NAME, \"iPVvYb\" or \"pT0Scc\")\n",
    "            for image in images:\n",
    "                if image.get_attribute('src') in image_urls:\n",
    "                    max_images += 1\n",
    "                    skips += 1\n",
    "                    break\n",
    "\n",
    "                if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "                    image_urls.add(image.get_attribute('src'))\n",
    "                    print(f\"Found {len(image_urls)}\")\n",
    "        scroll_down(wd)\n",
    "\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "# Function to download images\n",
    "def download_image(download_path, url, file_name):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file)\n",
    "        file_path = download_path + file_name\n",
    "\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            image.save(f, \"JPEG\")\n",
    "\n",
    "        print(\"Success\")\n",
    "    except Exception as e:\n",
    "        print('FAILED -', e)\n",
    "    \n",
    "\n",
    "# Function to start the download process\n",
    "def start_download():\n",
    "    max_images = int(number_of_images_entry.get())\n",
    "    search_term = search_term_entry.get()\n",
    "    download_path = download_path_label.cget(\"text\").replace(\"Download Path: \", \"\")\n",
    "\n",
    "    if not download_path.endswith(\"/\"):\n",
    "        download_path += \"/\"\n",
    "\n",
    "    url = create_google_images_url(search_term)\n",
    "\n",
    "    # Specify the path to your chromedriver.exe\n",
    "    PATH = \" \"\n",
    "    service = Service(PATH)\n",
    "    wd = webdriver.Chrome(service=service)\n",
    "\n",
    "    urls = get_images_from_google(wd, url, 1, max_images)\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        download_image(download_path, url, str(i) + \".jpg\")\n",
    "\n",
    "    wd.quit()\n",
    "\n",
    "# Function to choose download path\n",
    "def choose_download_path():\n",
    "    selected_folder = filedialog.askdirectory()\n",
    "    download_path_label.config(text=f\"Download Path: {selected_folder}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tkinter GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Downloader\")\n",
    "\n",
    "tk.Label(root, text=\"Search Term:\").pack()\n",
    "search_term_entry = tk.Entry(root)\n",
    "search_term_entry.pack()\n",
    "\n",
    "tk.Label(root, text=\"Number of Images:\").pack()\n",
    "number_of_images_entry = tk.Entry(root)\n",
    "number_of_images_entry.pack()\n",
    "\n",
    "download_path_label = tk.Label(root, text=\"Download Path: Not selected\")\n",
    "download_path_label.pack()\n",
    "\n",
    "choose_folder_button = tk.Button(root, text=\"Choose Download Path\", command=choose_download_path)\n",
    "choose_folder_button.pack()\n",
    "\n",
    "start_button = tk.Button(root, text=\"Start Download\", command=start_download)\n",
    "start_button.pack()\n",
    "print(\"....Done....\\n Close App\")\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# Function to create a Google Images URL from the search term\n",
    "def create_google_images_url(search_term):\n",
    "    base_url = \"https://www.google.com/search?tbm=isch&q=\"\n",
    "    query = quote_plus(search_term)\n",
    "    return f\"{base_url}{query}\"\n",
    "\n",
    "# Function to get images from Google\n",
    "def get_images_from_google(wd, url, delay, max_images):\n",
    "    def scroll_down(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    wd.get(url)\n",
    "    image_urls = set()\n",
    "    last_refresh = time.time()\n",
    "\n",
    "    while len(image_urls) < max_images:\n",
    "        if time.time() - last_refresh > 30:  # Refresh page every 30 seconds\n",
    "            wd.refresh()\n",
    "            last_refresh = time.time()\n",
    "            continue\n",
    "\n",
    "        scroll_down(wd)\n",
    "        thumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "        for img in thumbnails[len(image_urls):]:\n",
    "            if len(image_urls) >= max_images:\n",
    "                break\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(delay)\n",
    "                images = wd.find_elements(By.CLASS_NAME, \"iPVvYb\" or \"pT0Scc\")\n",
    "                for image in images:\n",
    "                    if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "                        image_urls.add(image.get_attribute('src'))\n",
    "                        if len(image_urls) >= max_images:\n",
    "                            break\n",
    "                print(f\"Found {len(image_urls)} images\")\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                continue\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "# Function to download images\n",
    "def download_image(download_path, url, file_name):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file)\n",
    "        file_path = download_path + file_name\n",
    "\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            image.save(f, \"JPEG\")\n",
    "\n",
    "        print(f\"Downloaded {file_name}\")\n",
    "    except Exception as e:\n",
    "        print('FAILED to download', file_name, '-', e)\n",
    "\n",
    "# Function to start the download process\n",
    "def start_download():\n",
    "    max_images = int(number_of_images_entry.get())\n",
    "    search_term = search_term_entry.get()\n",
    "    download_path = download_path_label.cget(\"text\").replace(\"Download Path: \", \"\")\n",
    "\n",
    "    if not download_path.endswith(\"/\"):\n",
    "        download_path += \"/\"\n",
    "\n",
    "    url = create_google_images_url(search_term)\n",
    "\n",
    "    # Specify the path to your chromedriver.exe\n",
    "    PATH = \"...\\chromedriver.exe\"\n",
    "    service = Service(PATH)\n",
    "    wd = webdriver.Chrome(service=service)\n",
    "\n",
    "    urls = get_images_from_google(wd, url, 3, max_images)\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        download_image(download_path, url, f\"{i}.jpg\")\n",
    "\n",
    "    wd.quit()\n",
    "    print(\"Download completed.\")\n",
    "\n",
    "# Function to choose download path\n",
    "def choose_download_path():\n",
    "    selected_folder = filedialog.askdirectory()\n",
    "    download_path_label.config(text=f\"Download Path: {selected_folder}\")\n",
    "\n",
    "# Tkinter GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Downloader\")\n",
    "\n",
    "tk.Label(root, text=\"Search Term:\").pack()\n",
    "search_term_entry = tk.Entry(root)\n",
    "search_term_entry.pack()\n",
    "\n",
    "tk.Label(root, text=\"Number of Images:\").pack()\n",
    "number_of_images_entry = tk.Entry(root)\n",
    "number_of_images_entry.pack()\n",
    "\n",
    "download_path_label = tk.Label(root, text=\"Download Path: Not selected\")\n",
    "download_path_label.pack()\n",
    "\n",
    "choose_folder_button = tk.Button(root, text=\"Choose Download Path\", command=choose_download_path)\n",
    "choose_folder_button.pack()\n",
    "\n",
    "start_button = tk.Button(root, text=\"Start Download\", command=start_download)\n",
    "start_button.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final + upload on Mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mega import Mega\n",
    "import tkinter as tk\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from urllib.parse import quote_plus\n",
    "from mega import Mega\n",
    "\n",
    "\n",
    "# Initialize MEGA API\n",
    "mega = Mega()\n",
    "email = ''  # Replace with your MEGA email\n",
    "password = ''  # Replace with your MEGA password\n",
    "m = mega.login(email, password)\n",
    "\n",
    "# Function to create a Google Images URL from the search term\n",
    "def create_google_images_url(search_term):\n",
    "    base_url = \"https://www.google.com/search?tbm=isch&q=\"\n",
    "    query = quote_plus(search_term)\n",
    "    return f\"{base_url}{query}\"\n",
    "\n",
    "# Function to get images from Google\n",
    "def get_images_from_google(wd, url, delay, max_images):\n",
    "    def scroll_down(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    wd.get(url)\n",
    "    image_urls = set()\n",
    "\n",
    "    while len(image_urls) < max_images:\n",
    "        scroll_down(wd)\n",
    "        thumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "        for img in thumbnails[len(image_urls):]:\n",
    "            if len(image_urls) >= max_images:\n",
    "                break\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(delay)\n",
    "                images = wd.find_elements(By.CLASS_NAME, \"iPVvYb\" or \"pT0Scc\")\n",
    "                for image in images:\n",
    "                    if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "                        image_urls.add(image.get_attribute('src'))\n",
    "                        if len(image_urls) >= max_images:\n",
    "                            break\n",
    "                print(f\"Found {len(image_urls)} images\")\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                continue\n",
    "        # scroll_down(wd)\n",
    "    return image_urls\n",
    "\n",
    "# Function to upload images to MEGA\n",
    "def upload_image_to_mega(image_content, folder_name, file_name):\n",
    "    try:\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file)\n",
    "        \n",
    "        # Convert RGBA to RGB if necessary\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        temp_file_path = str(path) + file_name\n",
    "        image.save(temp_file_path, \"JPEG\")\n",
    "\n",
    "        # Create folder in MEGA if it doesn't exist\n",
    "        folder = m.find(folder_name)\n",
    "        if folder is None:\n",
    "            folder = m.create_folder(folder_name)\n",
    "\n",
    "        # Upload the file\n",
    "        m.upload(temp_file_path, folder[0])\n",
    "        print(f\"Uploaded {file_name} to MEGA\")\n",
    "    except Exception as e:\n",
    "        print('FAILED to upload', file_name, '-', e)\n",
    "        \n",
    "              \n",
    "\n",
    "# Function to start the download process\n",
    "def start_download():\n",
    "    max_images = int(number_of_images_entry.get())\n",
    "    search_term = search_term_entry.get()\n",
    "    folder_name = search_term.replace(\" \", \"_\")  # Folder name based on search term\n",
    "\n",
    "    url = create_google_images_url(search_term)\n",
    "\n",
    "    # Specify the path to your chromedriver.exe\n",
    "    PATH = \"...\\chromedriver.exe\"\n",
    "    service = Service(PATH)\n",
    "    wd = webdriver.Chrome(service=service)\n",
    "\n",
    "    urls = get_images_from_google(wd, url, 3, max_images)\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            image_content = requests.get(url).content\n",
    "            upload_image_to_mega(image_content, folder_name, f\"{folder_name}_{i}.jpg\")\n",
    "        except Exception as e:\n",
    "            print('Error downloading or uploading image:', e)\n",
    "\n",
    "    wd.quit()\n",
    "    print(\"Download and upload completed.\")\n",
    "\n",
    "# Tkinter GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Downloader\")\n",
    "\n",
    "tk.Label(root, text=\"Search Term:\").pack()\n",
    "search_term_entry = tk.Entry(root)\n",
    "search_term_entry.pack()\n",
    "\n",
    "tk.Label(root, text=\"Number of Images:\").pack()\n",
    "number_of_images_entry = tk.Entry(root)\n",
    "number_of_images_entry.pack()\n",
    "\n",
    "tk.Label(root, text=\"folder:\").pack()\n",
    "path = tk.Entry(root)\n",
    "path.pack()\n",
    "\n",
    "start_button = tk.Button(root, text=\"Start Download\", command=start_download)\n",
    "start_button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
